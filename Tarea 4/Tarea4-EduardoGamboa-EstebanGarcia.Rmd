---
title: 'Tarea #4 Web mining y clustering'
author: "Eduardo Gamboa - Esteban García"
date: "5/17/2020"
output: html_document
---

```{r setup, include=FALSE}
 library(tibble)
 library(stringr)
 library(rvest)
 library(FactoMineR)
 library(ggplot2)
 library(cluster)
 library(factoextra)
 library(cluster)
 library(fpc)
```

# Fase de entendimiento de los datos

Para está asignación se usará la información disponible en: https://www.worldometers.info/gdp/gdp-by-country/

En ese sitio se encuentran los índices de producto interno bruto (PIB) mundial, publicados por el Banco Mundial. Allí Podemos encontrar la siguiente información en formato tabla html:

* *Country:* nombre del país
* *GDP nominal:* PIB 
* *GDP abbrev:* PIB abreviado, 
* *GDP growth:* Crecimiento porcentual del PIB
* *Population:* tamaño de población 
* *Share of World GDP:* porcentaje del GDP mundial


```{r}
#web data source
url<-'https://www.worldometers.info/gdp/gdp-by-country/'

#Read page
xmlPage<- read_html(url,encoding = 'UTF-8')  
  
#Get tables
tablesList<- html_table(xmlPage,fill=TRUE)
  
#Get the first table
table<- tablesList[[1]]
  
head(table)
```
# Preparación de los datos

## Selección de datos

Mantenemos todas las columnas excepto "GDP abbrev" pues la columna "GDP Nominal"  representa la misma información en un formato númerico puro. 

```{r}
#Remove column "GDP Nominal" 
drop <- c("GDP (abbrev.)")
table = table[,!(names(table) %in% drop)]
head(table)
```
## Limpieza de datos

Se hace uso de expresiones regulares para limpiar los datos:

De "GDP (nominal, 2017)" se eliminan los signos "$" y ","

```{r}
GDP<- str_remove(table$`GDP (nominal, 2017)`,'\\s*\\$')
GDP<- str_remove_all(GDP,',')
table$`GDP (nominal, 2017)`<-GDP
```

De "GDP growth" se elimina el signo "%"
```{r}
GDPG<- str_remove(table$`GDP  growth`,'\\s*\\%')
table$`GDP  growth` <- GDPG
```

De "Population" se eliminan todas las ","
```{r}
POPULATION<- str_remove_all(table$`Population (2017)`, ',')
table$`Population (2017)` <- POPULATION
```

De "GDP per capita" se eliminan los signos "$" y ","
```{r}
GDPPC<- str_remove(table$`GDP  per capita`,'\\s*\\$')
GDPPC<- str_remove(GDPPC,'\\s*\\%')
GDPPC<- str_remove_all(GDPPC,',')
table$`GDP  per capita` <- GDPPC
```

De "Share of World GDP" se elimina el signo "%"
```{r}
SWGDP<- str_remove(table$`Share of World GDP`,'\\s*\\%')
table$`Share of World GDP` <- SWGDP
```

## Construcción de datos
No es necesario construir nuevos datos

## Transformaciones aplicadas a los datos

Se transforman todas las columnas de "chr" a "numeric" para que puedan ser procesadas por los algoritmos de clustering. Además, se elimina una columna que es numerica y no es necesaria. 

```{r}
cleanTable<- data.frame(table[-c(1)])
cleanTable[,2:6] <- sapply(cleanTable[,2:6],as.numeric)
rownames(cleanTable) <- cleanTable$Country
cleanTable$Country <- NULL
```

dataframe con los datos limpios:
```{r}
head(cleanTable)
```

# Fase de modelado

## Selección de técnicas

Para el presente trabajo se procederá a utilizar dos algoritmos de clutering diferentes, a saber, el algoritmo de Clustering jerárquico, y un algoritmo de agrupamientos k-medias.

Para el caso del cluter jerárquico, se utillizará una distancia Euclidiana, y para poder agrupar dos elementos se utiliza el promedio de distancia entre los mismos. 

## Construcción de cada modelo

### Clustering Jerárquico
```{r}
# calculo de las distancias, utilizando la distancia L2, o euclidiana
matriz_distancias<- dist(cleanTable,method = 'euclidean')

clustJer_conAvg<- hclust(matriz_distancias,method = 'average')
plot(clustJer_conAvg)
```

Es posible crear los grupos a partir del dendograma. Por ejemplo, si necesitamos 3 grupos: 
```{r}
cut <- cutree(clustJer_conAvg, k = 3); 
plot(clustJer_conAvg, hang = -1)
rect.hclust(clustJer_conAvg, k = 3)
```

Es claro ver que la mayor parte de los países forman parte forman parte del mismo grupo. A fin de poder observalo de manera mas sencilla, se imprimen los grupos creados:
```{r}
cut
```

Es claro ver que los unicos paises que no pertenecen al grupo 3 son Estados Unidos y China, y los mismos forman grupos independientes entre si. Se forma, con tal de poder realizar comparaciones, 10 grupos con el mismo dendograma

```{r}
cut_10<- cutree(clustJer_conAvg, k = 10); 
plot(clustJer_conAvg, hang = -1)
rect.hclust(clustJer_conAvg, k = 10)

```

Los grupos siguen siendo grandes, se procede a imprimirlos: 
```{r}
cut_10
```

Estados Unidos y China siguen con el mismo comportamiento, sin embargo, ahora Japón y Alemania se prosentan en un grupo por país. La mayor parte de los países forman parte del grupo 10. 

### K medias

Se procede a craer un modelo de K medias, con los mismos datos. 

__NOTA__ debido a la naturaleza aleatoria del algoritmo, se procede a setear una semilla para tener datos repetibles

```{r}
set.seed(860529)
```


Se ejecuta el algoritmo con dos tamaños de k, los 3 y 10 grupos anteriores
```{r}
clusters_3 <- kmeans(cleanTable,3,nstart=20)
clusters_10 <- kmeans(cleanTable,10,nstart=20)

descClusters_3<- data.frame(clusters_3$size,clusters_3$centers)
descClusters_3

descClusters_10<- data.frame(clusters_10$size,clusters_10$centers)
descClusters_10
```

Con ambos modelos, se grafican los ds agrupamientos, primeramente el de 3 agrupamientos
```{r}
clusplot(cleanTable, clusters_3$cluster, color=TRUE, shade=TRUE, 
         labels=2, lines=0)
```

A su vez, se muestran parte de los posibles agrupam
ientos generados
```{r}
resultado_3 <- data.frame(clusters_3$cluster,cleanTable)
resultado_3
```

Es posible ver que Estados Unidos y China quedaron en el mismo grupo en este caso, y apartados del resto de países, pues sus centroides estan mas alejados. Sin embargo, los grupos de los demás paises estan muy juntos, lo que hace que dichos agrupamientos esten muy juntos entre si. 


Para el caso del algoritmo con 10 agrupamientos: 

```{r}
clusplot(cleanTable, clusters_10$cluster, color=TRUE, shade=TRUE, 
         labels=2, lines=0)
```

Y si vemos la tabla de resultados:

```{r}
resultado_10 <- data.frame(clusters_10$cluster,cleanTable)
resultado_10
```

Estados Unidos y china estan igualmente en el un mismo grupo. Los centroides tomados son muy similares, por ende, tambien tiene el efecto de colocar a todos los paises cerca y agrupados hacia la izquierda. Esto no cambia aun si tomamos diferentes numeros para la cantidad de grupos a formar

## Evaluación de los modelos
Se ve claro que los modelos producen salidas difernetes. En el caso del clustering jerárquico, tiende a separar países que son muy diferentes entre si. Esto se puede apreciar en el caso de China y Estados Unidos, que conforman un grupo cada uno con solo dichos países. Ambos países distan mucho, en espcial en la población, lo que hace posible, a nivel intuitivo, que pertenezcan a grupos diferentes. Sin embargo, el algoritmo de k-medias trata con la distancia entre los vectores, por lo que puede parecer agrupar a los paises 

Por otro lado, k medias permite discernir que dos o mas grupos son mas bien muy cercanos, por lo que no tiene mucho sentido separarlos. 